{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c67ce5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "f6c67ce5",
    "outputId": "123897fe-3a4d-41a8-d9f3-85b4e493e424"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e153c35",
   "metadata": {
    "id": "0e153c35"
   },
   "source": [
    "# Imports Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f6e2fd0",
   "metadata": {
    "id": "8f6e2fd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Atefe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Atefe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "nltk.download('punkt')\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "nltk.download('stopwords')\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d219090",
   "metadata": {
    "id": "0d219090"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D, Dense, LSTM, Conv1D, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04fcb01",
   "metadata": {
    "id": "a04fcb01"
   },
   "outputs": [],
   "source": [
    "# pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14d4c1",
   "metadata": {
    "id": "9a14d4c1"
   },
   "source": [
    "# Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b51316",
   "metadata": {
    "id": "24b51316"
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv('twitter_training.csv', encoding='iso-8859-1')\n",
    "validation = pd.read_csv('twitter_validation.csv', encoding='iso-8859-1')\n",
    "test = pd.read_csv('twitter_test.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d108cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57d108cc",
    "outputId": "b18beded-aaed-4696-c858-ffc2cd614349",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74682 entries, 0 to 74681\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Tweet ID       74682 non-null  int64 \n",
      " 1   entity         74682 non-null  object\n",
      " 2   sentiment      74682 non-null  object\n",
      " 3   Tweet content  73996 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "training.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "908e0bec",
   "metadata": {
    "id": "908e0bec"
   },
   "outputs": [],
   "source": [
    "train_content_values=training['Tweet content'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2cbda23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "e2cbda23",
    "outputId": "9ae542cc-45e8-47e7-8030-d5e9c1202ff2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tweet ID       entity sentiment  \\\n",
       "0      2401  Borderlands  Positive   \n",
       "1      2401  Borderlands  Positive   \n",
       "2      2401  Borderlands  Positive   \n",
       "3      2401  Borderlands  Positive   \n",
       "4      2401  Borderlands  Positive   \n",
       "\n",
       "                                       Tweet content  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230dadd8",
   "metadata": {
    "id": "230dadd8"
   },
   "outputs": [],
   "source": [
    "# Removing the unnecessary columns.\n",
    "training = training[['Tweet ID','sentiment','Tweet content']]\n",
    "validation = validation[['Tweet ID','sentiment','Tweet content']]\n",
    "test = test[['Tweet ID','sentiment','Tweet content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccd99f37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "ccd99f37",
    "outputId": "12266270-db6a-473e-db79-70831dbd2b55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>9200</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74682 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID sentiment                                      Tweet content\n",
       "0          2401  Positive  im getting on borderlands and i will murder yo...\n",
       "1          2401  Positive  I am coming to the borders and I will kill you...\n",
       "2          2401  Positive  im getting on borderlands and i will kill you ...\n",
       "3          2401  Positive  im coming on borderlands and i will murder you...\n",
       "4          2401  Positive  im getting on borderlands 2 and i will murder ...\n",
       "...         ...       ...                                                ...\n",
       "74677      9200  Positive  Just realized that the Windows partition of my...\n",
       "74678      9200  Positive  Just realized that my Mac window partition is ...\n",
       "74679      9200  Positive  Just realized the windows partition of my Mac ...\n",
       "74680      9200  Positive  Just realized between the windows partition of...\n",
       "74681      9200  Positive  Just like the windows partition of my Mac is l...\n",
       "\n",
       "[74682 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63d7c065",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "63d7c065",
    "outputId": "7e6014bf-f1ad-4f0e-9e74-9ce027611394"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5328</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@BlizzardCS whatâs going on with Hearthstone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7618</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@EAMaddenNFL is there a reason OFFLINE franchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7108</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Johnson &amp; Johnson is about to enter phase 3 tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10008</td>\n",
       "      <td>Negative</td>\n",
       "      <td>How is banning #PUBG going to fix anything? Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>I played this interesting quiz on Amazon - Try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4891</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>â­ï¸ Toronto is the arts and culture capital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4359</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2652</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Today sucked so itâs time to drink wine n pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>8069</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Bought a fraction of Microsoft today. Small wins.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>6960</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet ID   sentiment                                      Tweet content\n",
       "0        5328    Negative  @BlizzardCS whatâs going on with Hearthstone...\n",
       "1        7618    Negative  @EAMaddenNFL is there a reason OFFLINE franchi...\n",
       "2        7108    Negative  Johnson & Johnson is about to enter phase 3 tr...\n",
       "3       10008    Negative  How is banning #PUBG going to fix anything? Al...\n",
       "4          49     Neutral  I played this interesting quiz on Amazon - Try...\n",
       "..        ...         ...                                                ...\n",
       "495      4891  Irrelevant  â­ï¸ Toronto is the arts and culture capital...\n",
       "496      4359  Irrelevant  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...\n",
       "497      2652    Positive  Today sucked so itâs time to drink wine n pl...\n",
       "498      8069    Positive  Bought a fraction of Microsoft today. Small wins.\n",
       "499      6960     Neutral  Johnson & Johnson to stop selling talc baby po...\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2db249e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "a2db249e",
    "outputId": "2d732115-2398-4d50-b312-4f1f29dd4b9e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3364</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I mentioned on Facebook that I was struggling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8312</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4371</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4433</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>8055</td>\n",
       "      <td>Positive</td>\n",
       "      <td>special shoutouts to microsoft excel 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>6787</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Dumb Luckyâï¸   (Fortnite Montage) youtu.be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3838</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Dang there goes my birthday present but maybe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2008</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>It was ab fab seeing the 6 bungalows built in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4096</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.7 million viewers? wtf? and cs:go has more t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet ID   sentiment                                      Tweet content\n",
       "0        3364  Irrelevant  I mentioned on Facebook that I was struggling ...\n",
       "1         352     Neutral  BBC News - Amazon boss Jeff Bezos rejects clai...\n",
       "2        8312    Negative  @Microsoft Why do I pay for WORD when it funct...\n",
       "3        4371    Negative  CSGO matchmaking is so full of closet hacking,...\n",
       "4        4433     Neutral  Now the President is slapping Americans in the...\n",
       "..        ...         ...                                                ...\n",
       "495      8055    Positive          special shoutouts to microsoft excel 2013\n",
       "496      6787  Irrelevant  Dumb Luckyâï¸   (Fortnite Montage) youtu.be...\n",
       "497      3838    Positive  Dang there goes my birthday present but maybe ...\n",
       "498      2008  Irrelevant  It was ab fab seeing the 6 bungalows built in ...\n",
       "499      4096     Neutral  1.7 million viewers? wtf? and cs:go has more t...\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13bdf9f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13bdf9f5",
    "outputId": "570cbb2c-1fbe-415b-8472-f4d2232220cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74682, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec9000b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eec9000b",
    "outputId": "107a208f-698c-414d-86a8-a24e27d03b9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63dab25d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63dab25d",
    "outputId": "f3508331-f78e-4762-c4c3-b1c518bf1db5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3d1e9",
   "metadata": {
    "id": "1db3d1e9"
   },
   "source": [
    "# convert categorical to numeric(Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e7d6a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80e7d6a1",
    "outputId": "7cb6a382-8919-4171-ac01-5e41f2c2960d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Neutral', 'Negative', 'Irrelevant'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dc85fe8",
   "metadata": {
    "id": "1dc85fe8"
   },
   "outputs": [],
   "source": [
    "training['sentiment'].replace(['Positive', 'Neutral', 'Negative', 'Irrelevant'],\n",
    "                        [0, 1, 2, 3], inplace=True)\n",
    "test['sentiment'].replace(['Positive', 'Neutral', 'Negative', 'Irrelevant'],\n",
    "                        [0, 1, 2, 3], inplace=True)\n",
    "validation['sentiment'].replace(['Positive', 'Neutral', 'Negative', 'Irrelevant'],\n",
    "                        [0, 1, 2, 3], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a233ccea",
   "metadata": {
    "id": "a233ccea"
   },
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672289b",
   "metadata": {
    "id": "5672289b"
   },
   "source": [
    "# Distribution of target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d5f9fd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "4d5f9fd4",
    "outputId": "a2537511-a1e4-4b2c-8675-806b0cea0b53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='sentiment',data=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "554f10e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.89624136 1.01924337 0.82825393 1.43729792]\n",
      "Class Weight Dictionary: {0: 0.8962413594470046, 1: 1.0192433671798231, 2: 0.8282539260047911, 3: 1.4372979214780601}\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights based on the training set\n",
    "c_weights = compute_class_weight('balanced', classes=np.unique(training['sentiment']), y=training['sentiment'])\n",
    "c_weightS_dict = dict(zip(np.unique(training['sentiment']), c_weights))\n",
    "\n",
    "# Print the computed class weights and the dictionary\n",
    "print(\"Class Weights:\", c_weights)\n",
    "print(\"Class Weight Dictionary:\", c_weightS_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a5b6f6e",
   "metadata": {
    "id": "4a5b6f6e"
   },
   "outputs": [],
   "source": [
    "# wc = WordCloud(max_words = 1000 , width = 1600 , height = 800,\n",
    "#               collocations=False).generate(\" \".join(data_pos))\n",
    "# plt.figure(figsize = (20,20))\n",
    "# plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85c47a0",
   "metadata": {
    "id": "b85c47a0"
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "779816f7",
   "metadata": {
    "id": "779816f7"
   },
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    # Check if the tweet is a non-null string\n",
    "    if isinstance(tweet, str) and not pd.isnull(tweet):\n",
    "\n",
    "        # remove URL\n",
    "        tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "        # convert to lower case alpha\n",
    "        tweet = tweet.lower()\n",
    "\n",
    "        # Remove short links (e.g., buff.ly/2WmmiP5)\n",
    "        tweet = re.sub(r'\\b(?:buff\\.ly|dlvr\\.it)/\\S+', \"\", tweet)\n",
    "\n",
    "        # Remove usernames\n",
    "        tweet = re.sub(r\"@[^\\s]+[\\s]?\", '', tweet)\n",
    "\n",
    "        # remove special characters for example {!,?,...}\n",
    "        tweet = re.sub('[^ a-zA-Z0-9]', '', tweet)\n",
    "\n",
    "        # remove Numbers\n",
    "        tweet = re.sub('[0-9]', '', tweet)\n",
    "\n",
    "        return tweet\n",
    "    else:\n",
    "        # If the tweet is NaN or not a string, return it unchanged\n",
    "        return tweet\n",
    "\n",
    "# Apply the clean_tweets function to the 'Tweet content' column\n",
    "training['Tweet content'] = training['Tweet content'].apply(clean_tweets)\n",
    "validation['Tweet content'] = validation['Tweet content'].apply(clean_tweets)\n",
    "test['Tweet content'] = test['Tweet content'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "836fa2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74682, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e40e8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atefe\\AppData\\Local\\Temp\\ipykernel_14668\\761347574.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tweet content'][i] = None\n"
     ]
    }
   ],
   "source": [
    "def remove_extra_spaces(df):\n",
    "    df['Tweet content'] = df['Tweet content'].str.strip()\n",
    "    for i in range(len(df)):\n",
    "        if df['Tweet content'][i]== '':\n",
    "            df['Tweet content'][i] = None \n",
    "    training.dropna(subset=['Tweet content'], inplace=True)\n",
    "    training.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "training = remove_extra_spaces(training)\n",
    "test = remove_extra_spaces(test)\n",
    "validation = remove_extra_spaces(validation)\n",
    "# training['Tweet content']=training['Tweet content'].str.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c25a45a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73610, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee00f373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training.to_csv('test', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffed3d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        im getting on borderlands and i will murder yo...\n",
       "1        i am coming to the borders and i will kill you...\n",
       "2        im getting on borderlands and i will kill you all\n",
       "3        im coming on borderlands and i will murder you...\n",
       "4        im getting on borderlands  and i will murder y...\n",
       "                               ...                        \n",
       "73605    just realized that the windows partition of my...\n",
       "73606    just realized that my mac window partition is ...\n",
       "73607    just realized the windows partition of my mac ...\n",
       "73608    just realized between the windows partition of...\n",
       "73609    just like the windows partition of my mac is l...\n",
       "Name: Tweet content, Length: 73610, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['Tweet content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfc04140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "618cfbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the stop words except \"not\"\n",
    "stop_words = stopwords.words(\"english\")\n",
    "whitelist = [\"n't\", \"not\"]\n",
    "filtered_list = [item for item in stop_words if item not in whitelist]\n",
    "# Define a function to remove stop words\n",
    "def remove_stop_words(word_list):\n",
    "    tweet_without_stopwords = [word for word in  \n",
    "                              word_list.split()\n",
    "                              if word.lower() not in filtered_list]\n",
    "    joined_tokens = [\" \".join(tweet_without_stopwords)]\n",
    "#     return tweet_without_stopwords\n",
    "    return joined_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33Xo9BFRTsEM",
   "metadata": {
    "id": "33Xo9BFRTsEM"
   },
   "outputs": [],
   "source": [
    "training['Tweet content'] = training['Tweet content'].apply(remove_stop_words)\n",
    "test['Tweet content'] = test['Tweet content'].apply(remove_stop_words)\n",
    "validation['Tweet content'] = validation['Tweet content'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d0f5cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>0</td>\n",
       "      <td>[im getting borderlands murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>0</td>\n",
       "      <td>[coming borders kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>0</td>\n",
       "      <td>[im getting borderlands kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>0</td>\n",
       "      <td>[im coming borderlands murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>0</td>\n",
       "      <td>[im getting borderlands murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73605</th>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>[realized windows partition mac like years beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73606</th>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>[realized mac window partition years behind nv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73607</th>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>[realized windows partition mac years behind n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73608</th>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>[realized windows partition mac like years beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73609</th>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>[like windows partition mac like years behind ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73610 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID  sentiment                                      Tweet content\n",
       "0          2401          0                    [im getting borderlands murder]\n",
       "1          2401          0                              [coming borders kill]\n",
       "2          2401          0                      [im getting borderlands kill]\n",
       "3          2401          0                     [im coming borderlands murder]\n",
       "4          2401          0                    [im getting borderlands murder]\n",
       "...         ...        ...                                                ...\n",
       "73605      9200          0  [realized windows partition mac like years beh...\n",
       "73606      9200          0  [realized mac window partition years behind nv...\n",
       "73607      9200          0  [realized windows partition mac years behind n...\n",
       "73608      9200          0  [realized windows partition mac like years beh...\n",
       "73609      9200          0  [like windows partition mac like years behind ...\n",
       "\n",
       "[73610 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbb763e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training.to_csv('clean_train', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25b6b37",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbe69dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stem the words\n",
    "ps = PorterStemmer()\n",
    "# Define a function to stem the words\n",
    "def stemming(word_list):\n",
    "    tweet_with_stem = []\n",
    "    split_list = [word for sentence in word_list for word in sentence.split()]\n",
    "    for w in split_list:\n",
    "        w = ps.stem(w)\n",
    "        tweet_with_stem.append(w)\n",
    "    return tweet_with_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a48edb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "training['Tweet content'] = training['Tweet content'].apply(stemming)\n",
    "test['Tweet content'] = test['Tweet content'].apply(stemming)\n",
    "validation['Tweet content'] = validation['Tweet content'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bed226b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>0</td>\n",
       "      <td>[im, get, borderland, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>0</td>\n",
       "      <td>[come, border, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>0</td>\n",
       "      <td>[im, get, borderland, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>0</td>\n",
       "      <td>[im, come, borderland, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>0</td>\n",
       "      <td>[im, get, borderland, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73605</th>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>[realiz, window, partit, mac, like, year, behi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73606</th>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>[realiz, mac, window, partit, year, behind, nv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73607</th>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>[realiz, window, partit, mac, year, behind, nv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73608</th>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>[realiz, window, partit, mac, like, year, behi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73609</th>\n",
       "      <td>9200</td>\n",
       "      <td>0</td>\n",
       "      <td>[like, window, partit, mac, like, year, behind...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73610 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID  sentiment                                      Tweet content\n",
       "0          2401          0                      [im, get, borderland, murder]\n",
       "1          2401          0                               [come, border, kill]\n",
       "2          2401          0                        [im, get, borderland, kill]\n",
       "3          2401          0                     [im, come, borderland, murder]\n",
       "4          2401          0                      [im, get, borderland, murder]\n",
       "...         ...        ...                                                ...\n",
       "73605      9200          0  [realiz, window, partit, mac, like, year, behi...\n",
       "73606      9200          0  [realiz, mac, window, partit, year, behind, nv...\n",
       "73607      9200          0  [realiz, window, partit, mac, year, behind, nv...\n",
       "73608      9200          0  [realiz, window, partit, mac, like, year, behi...\n",
       "73609      9200          0  [like, window, partit, mac, like, year, behind...\n",
       "\n",
       "[73610 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "974d0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer = WordNetLemmatizer()\n",
    "# with tqdm(total=len(training['Tweet content'])) as pbar:\n",
    "#     for tweet in training['Tweet content']:\n",
    "#         lemmatized = [lemmatizer.lemmatize(word) for word in tweet]\n",
    "#         tweets.append(lemmatized)\n",
    "#         pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20447d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1674d066",
   "metadata": {},
   "source": [
    "# Word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800cba83",
   "metadata": {},
   "source": [
    "# W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad585839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hello', 0.9060459733009338),\n",
       " ('hey', 0.8979060053825378),\n",
       " ('ghostrecon', 0.8853891491889954)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = training['Tweet content']\n",
    "SIZE = 50\n",
    "model = gensim.models.Word2Vec(X_train\n",
    ", min_count=1\n",
    ", vector_size=SIZE\n",
    ", window=5\n",
    ", workers=4)\n",
    "model.wv.most_similar('hi', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d48f55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_w2v_vector(w2v_dict, tweet):\n",
    "    list_of_word_vectors = [w2v_dict[w] for w in tweet if w in w2v_dict.key_to_index.keys()]\n",
    "    if len(list_of_word_vectors) == 0:\n",
    "        result = [0.0]*SIZE\n",
    "    else:\n",
    "        result = np.sum(list_of_word_vectors, axis=0) / len(list_of_word_vectors)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f437b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "training['W2v'] = training['Tweet content'].apply(lambda x: compute_avg_w2v_vector(model.wv, x))\n",
    "test['W2v'] = test['Tweet content'].apply(lambda x: compute_avg_w2v_vector(model.wv, x))\n",
    "validation['W2v'] = validation['Tweet content'].apply(lambda x: compute_avg_w2v_vector(model.wv, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ff6330a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training['W2v'][1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a647666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['glove'] = test['Tweet content'].apply(embedd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ae91370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['glove'] = validation['Tweet content'].apply(embedd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "38d7c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "training['glove'] = training['Tweet content'].apply(embedd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "dffb7754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73610,)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['glove'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5dc9a4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training['glove'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ff383bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.dropna(subset=['glove'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d3e5529a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73610,)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['glove'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609e512",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f209d2",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f95b0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={0: 0.8962413594470046,\n",
       "                                     1: 1.0192433671798231,\n",
       "                                     2: 0.8282539260047911,\n",
       "                                     3: 1.4372979214780601},\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={0: 0.8962413594470046,\n",
       "                                     1: 1.0192433671798231,\n",
       "                                     2: 0.8282539260047911,\n",
       "                                     3: 1.4372979214780601},\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 0.8962413594470046,\n",
       "                                     1: 1.0192433671798231,\n",
       "                                     2: 0.8282539260047911,\n",
       "                                     3: 1.4372979214780601},\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create X_train and y_train\n",
    "X_train_RF = np.vstack(training['W2v'].to_numpy())\n",
    "y_train_RF = np.array(training['sentiment'])\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42,class_weight=c_weightS_dict)\n",
    "rf_model.fit(X_train_RF, y_train_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06707c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_RF = np.vstack(test['W2v'].to_numpy())\n",
    "y_test_RF = np.array(test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cfd6e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "rf_predictions = rf_model.predict(X_test_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef98b39c",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7f92cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Precision: 0.8883871126353703\n",
      "RF Recall: 0.8788929492206585\n",
      "RF F1-Score: 0.8822629942684953\n",
      "RF Confusion Matrix:\n",
      "[[133   6   5   4]\n",
      " [  9 117   8   0]\n",
      " [  1   6 117   2]\n",
      " [  7   2   8  75]]\n"
     ]
    }
   ],
   "source": [
    "# Replace 'binary' with the desired average setting ('micro', 'macro', 'weighted', or None)\n",
    "average_setting = 'macro'\n",
    "# Calculate precision, recall, and F1-score with the specified average setting and conf_matrix\n",
    "precision = precision_score(y_test_RF, rf_predictions, average=average_setting)\n",
    "recall = recall_score(y_test_RF, rf_predictions, average=average_setting)\n",
    "f1 = f1_score(y_test_RF, rf_predictions, average=average_setting)\n",
    "conf_matrix = confusion_matrix(y_test_RF, rf_predictions)\n",
    "\n",
    "# Print additional metrics\n",
    "print(\"RF Precision:\", precision)\n",
    "print(\"RF Recall:\", recall)\n",
    "print(\"RF F1-Score:\", f1)\n",
    "print(\"RF Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "799f18e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy: 0.884\n",
      "RF Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89       148\n",
      "           1       0.89      0.87      0.88       134\n",
      "           2       0.85      0.93      0.89       126\n",
      "           3       0.93      0.82      0.87        92\n",
      "\n",
      "    accuracy                           0.88       500\n",
      "   macro avg       0.89      0.88      0.88       500\n",
      "weighted avg       0.89      0.88      0.88       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "rf_accuracy = accuracy_score(y_test_RF, rf_predictions)\n",
    "print(\"RF Accuracy:\", rf_accuracy)\n",
    "print(\"RF Classification Report:\")\n",
    "print(classification_report(y_test_RF, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2591486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_val and y_val\n",
    "X_val_RF = np.vstack(validation['W2v'].to_numpy())\n",
    "y_val_RF = np.array(validation['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed13ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the Twitter-validation dataset\n",
    "validation['predicted RF W2v'] = rf_model.predict(X_val_RF)\n",
    "# Save the result to an Excel file\n",
    "validation.to_excel('RF_validation_w2v.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "067c13f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "      <th>W2v</th>\n",
       "      <th>predicted RF W2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5328</td>\n",
       "      <td>2</td>\n",
       "      <td>[what, go, hearthston, ipad, delet, app, redow...</td>\n",
       "      <td>[0.10745893, -0.6231127, -0.01949474, 0.420772...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7618</td>\n",
       "      <td>2</td>\n",
       "      <td>[reason, offlin, franchis, lag, much, everi, p...</td>\n",
       "      <td>[-0.014914964, -0.7025625, -0.26694527, 0.0071...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7108</td>\n",
       "      <td>2</td>\n",
       "      <td>[johnson, johnson, enter, phase, trial, covid,...</td>\n",
       "      <td>[0.17915028, -0.08081439, 0.9860153, -0.341124...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10008</td>\n",
       "      <td>2</td>\n",
       "      <td>[ban, pubg, go, fix, anyth, gonna, make, every...</td>\n",
       "      <td>[0.14647946, -0.3018616, 0.040271103, 0.021447...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>[play, interest, quiz, amazon, tri, luck, chan...</td>\n",
       "      <td>[-0.09565098, -1.7299399, 0.42340872, 0.649577...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4891</td>\n",
       "      <td>3</td>\n",
       "      <td>[toronto, art, cultur, capit, canada, wonder, ...</td>\n",
       "      <td>[0.08433795, -0.4540689, 0.29474062, -0.054828...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4359</td>\n",
       "      <td>3</td>\n",
       "      <td>[actual, good, move, tot, bring, viewersi, one...</td>\n",
       "      <td>[0.102719866, -0.69867307, -0.09255285, 0.4414...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2652</td>\n",
       "      <td>0</td>\n",
       "      <td>[today, suck, time, drink, wine, n, play, bord...</td>\n",
       "      <td>[0.03667931, -0.6240968, -0.110848814, 0.68520...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>8069</td>\n",
       "      <td>0</td>\n",
       "      <td>[bought, fraction, microsoft, today, small, win]</td>\n",
       "      <td>[-0.13981943, -1.5053986, 0.4236864, -0.214958...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>6960</td>\n",
       "      <td>1</td>\n",
       "      <td>[johnson, johnson, stop, sell, talc, babi, pow...</td>\n",
       "      <td>[0.43969634, 0.18508025, 1.6390095, -0.754843,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet ID  sentiment                                      Tweet content  \\\n",
       "0        5328          2  [what, go, hearthston, ipad, delet, app, redow...   \n",
       "1        7618          2  [reason, offlin, franchis, lag, much, everi, p...   \n",
       "2        7108          2  [johnson, johnson, enter, phase, trial, covid,...   \n",
       "3       10008          2  [ban, pubg, go, fix, anyth, gonna, make, every...   \n",
       "4          49          1  [play, interest, quiz, amazon, tri, luck, chan...   \n",
       "..        ...        ...                                                ...   \n",
       "495      4891          3  [toronto, art, cultur, capit, canada, wonder, ...   \n",
       "496      4359          3  [actual, good, move, tot, bring, viewersi, one...   \n",
       "497      2652          0  [today, suck, time, drink, wine, n, play, bord...   \n",
       "498      8069          0   [bought, fraction, microsoft, today, small, win]   \n",
       "499      6960          1  [johnson, johnson, stop, sell, talc, babi, pow...   \n",
       "\n",
       "                                                   W2v  predicted RF W2v  \n",
       "0    [0.10745893, -0.6231127, -0.01949474, 0.420772...                 2  \n",
       "1    [-0.014914964, -0.7025625, -0.26694527, 0.0071...                 2  \n",
       "2    [0.17915028, -0.08081439, 0.9860153, -0.341124...                 2  \n",
       "3    [0.14647946, -0.3018616, 0.040271103, 0.021447...                 2  \n",
       "4    [-0.09565098, -1.7299399, 0.42340872, 0.649577...                 1  \n",
       "..                                                 ...               ...  \n",
       "495  [0.08433795, -0.4540689, 0.29474062, -0.054828...                 3  \n",
       "496  [0.102719866, -0.69867307, -0.09255285, 0.4414...                 3  \n",
       "497  [0.03667931, -0.6240968, -0.110848814, 0.68520...                 0  \n",
       "498  [-0.13981943, -1.5053986, 0.4236864, -0.214958...                 0  \n",
       "499  [0.43969634, 0.18508025, 1.6390095, -0.754843,...                 1  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b3f35",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d9d1d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Correct Predictions: 453\n"
     ]
    }
   ],
   "source": [
    "result_RF = pd.read_excel('RF_validation_w2v.xlsx')\n",
    "true_sentiment = result_RF['sentiment']\n",
    "predicted_sentiment = result_RF['predicted RF W2v']\n",
    "# Calculate the number of correct predictions\n",
    "correct_predictions = sum(true_sentiment == predicted_sentiment)\n",
    "# Print the number of correct predictions\n",
    "print(f'Number of Correct Predictions: {correct_predictions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff8aa48",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab97c6",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5fa67677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_train and y_train\n",
    "X_train_AB = np.vstack(training['W2v'].to_numpy())\n",
    "y_train_AB = np.array(training['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc13615a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a base classifier\n",
    "base_classifier = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Create AdaBoost model with sample weights\n",
    "adaboost_model = AdaBoostClassifier(base_classifier, n_estimators=50, random_state=42)\n",
    "sample_weights = np.array([c_weightS_dict[y] for y in y_train_AB])\n",
    "adaboost_model.fit(X_train_AB, y_train_AB, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "00d2d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_AB = np.vstack(test['W2v'].to_numpy())\n",
    "y_test_AB = np.array(test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4b6efb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "ab_predictions = adaboost_model.predict(X_test_AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb11870",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "63f41e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB Precision: 0.484769507907985\n",
      "AB Recall: 0.48875365005313093\n",
      "AB F1-Score: 0.4832265448990143\n",
      "AB Confusion Matrix:\n",
      "[[76 25 23 24]\n",
      " [21 51 24 38]\n",
      " [14 16 83 13]\n",
      " [24 14 17 37]]\n"
     ]
    }
   ],
   "source": [
    "# Replace 'binary' with the desired average setting ('micro', 'macro', 'weighted', or None)\n",
    "average_setting = 'macro'\n",
    "# Calculate precision, recall, and F1-score with the specified average setting and conf_matrix\n",
    "precision = precision_score(y_test_AB, ab_predictions, average=average_setting)\n",
    "recall = recall_score(y_test_AB, ab_predictions, average=average_setting)\n",
    "f1 = f1_score(y_test_AB, ab_predictions, average=average_setting)\n",
    "conf_matrix = confusion_matrix(y_test_AB, ab_predictions)\n",
    "\n",
    "# Print additional metrics\n",
    "print(\"AB Precision:\", precision)\n",
    "print(\"AB Recall:\", recall)\n",
    "print(\"AB F1-Score:\", f1)\n",
    "print(\"AB Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9977deea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB Accuracy: 0.494\n",
      "AB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.51      0.54       148\n",
      "           1       0.48      0.38      0.42       134\n",
      "           2       0.56      0.66      0.61       126\n",
      "           3       0.33      0.40      0.36        92\n",
      "\n",
      "    accuracy                           0.49       500\n",
      "   macro avg       0.48      0.49      0.48       500\n",
      "weighted avg       0.50      0.49      0.49       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "ab_accuracy = accuracy_score(y_test_AB, ab_predictions)\n",
    "print(\"AB Accuracy:\", ab_accuracy)\n",
    "print(\"AB Classification Report:\")\n",
    "print(classification_report(y_test_AB, ab_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "45d02b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_val and y_val\n",
    "X_val_AB = np.vstack(validation['W2v'].to_numpy())\n",
    "y_val_AB = np.array(validation['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c7955bbe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Make predictions on the Twitter-validation dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m validation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted AB W2v\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mab_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_RF\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Save the result to an Excel file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m validation\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAB_validation_w2v.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "# Make predictions on the Twitter-validation dataset\n",
    "validation['predicted AB W2v'] = ab_predictions(X_val_AB)\n",
    "# Save the result to an Excel file\n",
    "validation.to_excel('AB_validation_w2v.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cb980626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "      <th>W2v</th>\n",
       "      <th>predicted RF W2v</th>\n",
       "      <th>predicted AB W2v</th>\n",
       "      <th>predicted LR W2v</th>\n",
       "      <th>predicted SVM W2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5328</td>\n",
       "      <td>2</td>\n",
       "      <td>[what, go, hearthston, ipad, delet, app, redow...</td>\n",
       "      <td>[0.10745893, -0.6231127, -0.01949474, 0.420772...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7618</td>\n",
       "      <td>2</td>\n",
       "      <td>[reason, offlin, franchis, lag, much, everi, p...</td>\n",
       "      <td>[-0.014914964, -0.7025625, -0.26694527, 0.0071...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7108</td>\n",
       "      <td>2</td>\n",
       "      <td>[johnson, johnson, enter, phase, trial, covid,...</td>\n",
       "      <td>[0.17915028, -0.08081439, 0.9860153, -0.341124...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10008</td>\n",
       "      <td>2</td>\n",
       "      <td>[ban, pubg, go, fix, anyth, gonna, make, every...</td>\n",
       "      <td>[0.14647946, -0.3018616, 0.040271103, 0.021447...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>[play, interest, quiz, amazon, tri, luck, chan...</td>\n",
       "      <td>[-0.09565098, -1.7299399, 0.42340872, 0.649577...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4891</td>\n",
       "      <td>3</td>\n",
       "      <td>[toronto, art, cultur, capit, canada, wonder, ...</td>\n",
       "      <td>[0.08433795, -0.4540689, 0.29474062, -0.054828...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4359</td>\n",
       "      <td>3</td>\n",
       "      <td>[actual, good, move, tot, bring, viewersi, one...</td>\n",
       "      <td>[0.102719866, -0.69867307, -0.09255285, 0.4414...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2652</td>\n",
       "      <td>0</td>\n",
       "      <td>[today, suck, time, drink, wine, n, play, bord...</td>\n",
       "      <td>[0.03667931, -0.6240968, -0.110848814, 0.68520...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>8069</td>\n",
       "      <td>0</td>\n",
       "      <td>[bought, fraction, microsoft, today, small, win]</td>\n",
       "      <td>[-0.13981943, -1.5053986, 0.4236864, -0.214958...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>6960</td>\n",
       "      <td>1</td>\n",
       "      <td>[johnson, johnson, stop, sell, talc, babi, pow...</td>\n",
       "      <td>[0.43969634, 0.18508025, 1.6390095, -0.754843,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet ID  sentiment                                      Tweet content  \\\n",
       "0        5328          2  [what, go, hearthston, ipad, delet, app, redow...   \n",
       "1        7618          2  [reason, offlin, franchis, lag, much, everi, p...   \n",
       "2        7108          2  [johnson, johnson, enter, phase, trial, covid,...   \n",
       "3       10008          2  [ban, pubg, go, fix, anyth, gonna, make, every...   \n",
       "4          49          1  [play, interest, quiz, amazon, tri, luck, chan...   \n",
       "..        ...        ...                                                ...   \n",
       "495      4891          3  [toronto, art, cultur, capit, canada, wonder, ...   \n",
       "496      4359          3  [actual, good, move, tot, bring, viewersi, one...   \n",
       "497      2652          0  [today, suck, time, drink, wine, n, play, bord...   \n",
       "498      8069          0   [bought, fraction, microsoft, today, small, win]   \n",
       "499      6960          1  [johnson, johnson, stop, sell, talc, babi, pow...   \n",
       "\n",
       "                                                   W2v  predicted RF W2v  \\\n",
       "0    [0.10745893, -0.6231127, -0.01949474, 0.420772...                 2   \n",
       "1    [-0.014914964, -0.7025625, -0.26694527, 0.0071...                 2   \n",
       "2    [0.17915028, -0.08081439, 0.9860153, -0.341124...                 2   \n",
       "3    [0.14647946, -0.3018616, 0.040271103, 0.021447...                 2   \n",
       "4    [-0.09565098, -1.7299399, 0.42340872, 0.649577...                 1   \n",
       "..                                                 ...               ...   \n",
       "495  [0.08433795, -0.4540689, 0.29474062, -0.054828...                 3   \n",
       "496  [0.102719866, -0.69867307, -0.09255285, 0.4414...                 3   \n",
       "497  [0.03667931, -0.6240968, -0.110848814, 0.68520...                 0   \n",
       "498  [-0.13981943, -1.5053986, 0.4236864, -0.214958...                 0   \n",
       "499  [0.43969634, 0.18508025, 1.6390095, -0.754843,...                 1   \n",
       "\n",
       "     predicted AB W2v  predicted LR W2v  predicted SVM W2v  \n",
       "0                   2                 2                  2  \n",
       "1                   2                 2                  2  \n",
       "2                   2                 1                  1  \n",
       "3                   2                 2                  2  \n",
       "4                   1                 1                  1  \n",
       "..                ...               ...                ...  \n",
       "495                 3                 1                  1  \n",
       "496                 3                 0                  0  \n",
       "497                 0                 0                  0  \n",
       "498                 0                 1                  1  \n",
       "499                 1                 1                  1  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e2bfc",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a1226429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Correct Predictions: 453\n"
     ]
    }
   ],
   "source": [
    "result_RF = pd.read_excel('AB_validation_w2v.xlsx')\n",
    "true_sentiment = result_RF['sentiment']\n",
    "predicted_sentiment = result_RF['predicted AB W2v']\n",
    "# Calculate the number of correct predictions\n",
    "correct_predictions = sum(true_sentiment == predicted_sentiment)\n",
    "# Print the number of correct predictions\n",
    "print(f'Number of Correct Predictions: {correct_predictions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc77f81",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ec2bb",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6967a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_train and y_train\n",
    "X_train_LR = np.vstack(training['W2v'].to_numpy())\n",
    "y_train_LR = np.array(training['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c3d1f1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight={0: 0.8962413594470046, 1: 1.0192433671798231,\n",
       "                                 2: 0.8282539260047911, 3: 1.4372979214780601},\n",
       "                   max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight={0: 0.8962413594470046, 1: 1.0192433671798231,\n",
       "                                 2: 0.8282539260047911, 3: 1.4372979214780601},\n",
       "                   max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight={0: 0.8962413594470046, 1: 1.0192433671798231,\n",
       "                                 2: 0.8282539260047911, 3: 1.4372979214780601},\n",
       "                   max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "lr_model = LogisticRegression(random_state=42, class_weight=c_weightS_dict,max_iter=1000)\n",
    "lr_model.fit(X_train_LR, y_train_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e8b4baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_LR = np.vstack(test['W2v'].to_numpy())\n",
    "y_test_LR = np.array(test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cbbd17cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "lr_predictions = lr_model.predict(X_test_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5623e854",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "483260e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Precision: 0.5017010480103178\n",
      "LR Recall: 0.5056573909591431\n",
      "LR F1-Score: 0.5031969114227602\n",
      "LR Confusion Matrix:\n",
      "[[83 33 11 21]\n",
      " [24 54 32 24]\n",
      " [15 18 80 13]\n",
      " [20 20 13 39]]\n"
     ]
    }
   ],
   "source": [
    "# Replace 'binary' with the desired average setting ('micro', 'macro', 'weighted', or None)\n",
    "average_setting = 'macro'\n",
    "# Calculate precision, recall, and F1-score with the specified average setting and conf_matrix\n",
    "precision = precision_score(y_test_LR, lr_predictions, average=average_setting)\n",
    "recall = recall_score(y_test_LR, lr_predictions, average=average_setting)\n",
    "f1 = f1_score(y_test_LR, lr_predictions, average=average_setting)\n",
    "conf_matrix = confusion_matrix(y_test_LR, lr_predictions)\n",
    "\n",
    "# Print additional metrics\n",
    "print(\"LR Precision:\", precision)\n",
    "print(\"LR Recall:\", recall)\n",
    "print(\"LR F1-Score:\", f1)\n",
    "print(\"LR Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "96fd545b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB Accuracy: 0.512\n",
      "AB Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.56      0.57       148\n",
      "           1       0.43      0.40      0.42       134\n",
      "           2       0.59      0.63      0.61       126\n",
      "           3       0.40      0.42      0.41        92\n",
      "\n",
      "    accuracy                           0.51       500\n",
      "   macro avg       0.50      0.51      0.50       500\n",
      "weighted avg       0.51      0.51      0.51       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "lr_accuracy = accuracy_score(y_test_LR, lr_predictions)\n",
    "print(\"AB Accuracy:\", lr_accuracy)\n",
    "print(\"AB Classification Report:\")\n",
    "print(classification_report(y_test_LR, lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e9ddc695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_val and y_val\n",
    "X_val_LR = np.vstack(validation['W2v'].to_numpy())\n",
    "y_val_LR = np.array(validation['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2459dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the Twitter-validation dataset\n",
    "validation['predicted LR W2v'] = lr_model.predict(X_val_LR)\n",
    "# Save the result to an Excel file\n",
    "validation.to_excel('LR_validation_w2v.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c3409f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "      <th>W2v</th>\n",
       "      <th>predicted RF W2v</th>\n",
       "      <th>predicted AB W2v</th>\n",
       "      <th>predicted LR W2v</th>\n",
       "      <th>predicted SVM W2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5328</td>\n",
       "      <td>2</td>\n",
       "      <td>[what, go, hearthston, ipad, delet, app, redow...</td>\n",
       "      <td>[0.10745893, -0.6231127, -0.01949474, 0.420772...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7618</td>\n",
       "      <td>2</td>\n",
       "      <td>[reason, offlin, franchis, lag, much, everi, p...</td>\n",
       "      <td>[-0.014914964, -0.7025625, -0.26694527, 0.0071...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7108</td>\n",
       "      <td>2</td>\n",
       "      <td>[johnson, johnson, enter, phase, trial, covid,...</td>\n",
       "      <td>[0.17915028, -0.08081439, 0.9860153, -0.341124...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10008</td>\n",
       "      <td>2</td>\n",
       "      <td>[ban, pubg, go, fix, anyth, gonna, make, every...</td>\n",
       "      <td>[0.14647946, -0.3018616, 0.040271103, 0.021447...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>[play, interest, quiz, amazon, tri, luck, chan...</td>\n",
       "      <td>[-0.09565098, -1.7299399, 0.42340872, 0.649577...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4891</td>\n",
       "      <td>3</td>\n",
       "      <td>[toronto, art, cultur, capit, canada, wonder, ...</td>\n",
       "      <td>[0.08433795, -0.4540689, 0.29474062, -0.054828...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4359</td>\n",
       "      <td>3</td>\n",
       "      <td>[actual, good, move, tot, bring, viewersi, one...</td>\n",
       "      <td>[0.102719866, -0.69867307, -0.09255285, 0.4414...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2652</td>\n",
       "      <td>0</td>\n",
       "      <td>[today, suck, time, drink, wine, n, play, bord...</td>\n",
       "      <td>[0.03667931, -0.6240968, -0.110848814, 0.68520...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>8069</td>\n",
       "      <td>0</td>\n",
       "      <td>[bought, fraction, microsoft, today, small, win]</td>\n",
       "      <td>[-0.13981943, -1.5053986, 0.4236864, -0.214958...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>6960</td>\n",
       "      <td>1</td>\n",
       "      <td>[johnson, johnson, stop, sell, talc, babi, pow...</td>\n",
       "      <td>[0.43969634, 0.18508025, 1.6390095, -0.754843,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet ID  sentiment                                      Tweet content  \\\n",
       "0        5328          2  [what, go, hearthston, ipad, delet, app, redow...   \n",
       "1        7618          2  [reason, offlin, franchis, lag, much, everi, p...   \n",
       "2        7108          2  [johnson, johnson, enter, phase, trial, covid,...   \n",
       "3       10008          2  [ban, pubg, go, fix, anyth, gonna, make, every...   \n",
       "4          49          1  [play, interest, quiz, amazon, tri, luck, chan...   \n",
       "..        ...        ...                                                ...   \n",
       "495      4891          3  [toronto, art, cultur, capit, canada, wonder, ...   \n",
       "496      4359          3  [actual, good, move, tot, bring, viewersi, one...   \n",
       "497      2652          0  [today, suck, time, drink, wine, n, play, bord...   \n",
       "498      8069          0   [bought, fraction, microsoft, today, small, win]   \n",
       "499      6960          1  [johnson, johnson, stop, sell, talc, babi, pow...   \n",
       "\n",
       "                                                   W2v  predicted RF W2v  \\\n",
       "0    [0.10745893, -0.6231127, -0.01949474, 0.420772...                 2   \n",
       "1    [-0.014914964, -0.7025625, -0.26694527, 0.0071...                 2   \n",
       "2    [0.17915028, -0.08081439, 0.9860153, -0.341124...                 2   \n",
       "3    [0.14647946, -0.3018616, 0.040271103, 0.021447...                 2   \n",
       "4    [-0.09565098, -1.7299399, 0.42340872, 0.649577...                 1   \n",
       "..                                                 ...               ...   \n",
       "495  [0.08433795, -0.4540689, 0.29474062, -0.054828...                 3   \n",
       "496  [0.102719866, -0.69867307, -0.09255285, 0.4414...                 3   \n",
       "497  [0.03667931, -0.6240968, -0.110848814, 0.68520...                 0   \n",
       "498  [-0.13981943, -1.5053986, 0.4236864, -0.214958...                 0   \n",
       "499  [0.43969634, 0.18508025, 1.6390095, -0.754843,...                 1   \n",
       "\n",
       "     predicted AB W2v  predicted LR W2v  predicted SVM W2v  \n",
       "0                   2                 2                  2  \n",
       "1                   2                 2                  2  \n",
       "2                   2                 1                  1  \n",
       "3                   2                 2                  2  \n",
       "4                   1                 1                  1  \n",
       "..                ...               ...                ...  \n",
       "495                 3                 1                  1  \n",
       "496                 3                 0                  0  \n",
       "497                 0                 0                  0  \n",
       "498                 0                 1                  1  \n",
       "499                 1                 1                  1  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9541d7c",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0804c902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Correct Predictions: 254\n"
     ]
    }
   ],
   "source": [
    "result_LR = pd.read_excel('LR_validation_w2v.xlsx')\n",
    "true_sentiment = result_LR['sentiment']\n",
    "predicted_sentiment = result_LR['predicted LR W2v']\n",
    "# Calculate the number of correct predictions\n",
    "correct_predictions = sum(true_sentiment == predicted_sentiment)\n",
    "# Print the number of correct predictions\n",
    "print(f'Number of Correct Predictions: {correct_predictions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c852627",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ca8db",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "587789d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_train and y_train\n",
    "X_train_SVM = np.vstack(training['W2v'].to_numpy())\n",
    "y_train_SVM = np.array(training['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "38a5a5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(class_weight={0: 0.8962413594470046, 1: 1.0192433671798231,\n",
       "                  2: 0.8282539260047911, 3: 1.4372979214780601},\n",
       "    kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight={0: 0.8962413594470046, 1: 1.0192433671798231,\n",
       "                  2: 0.8282539260047911, 3: 1.4372979214780601},\n",
       "    kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(class_weight={0: 0.8962413594470046, 1: 1.0192433671798231,\n",
       "                  2: 0.8282539260047911, 3: 1.4372979214780601},\n",
       "    kernel='linear')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM Model\n",
    "svm_model = SVC(kernel='linear', C=1.0, class_weight=c_weightS_dict)\n",
    "svm_model.fit(X_train_SVM, y_train_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "36d13d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_SVM = np.vstack(test['W2v'].to_numpy())\n",
    "y_test_SVM = np.array(test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a308f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "svm_predictions = svm_model.predict(X_test_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9293afc9",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "256be3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Precision: 0.5153990344614074\n",
      "LR Recall: 0.5231688244747946\n",
      "LR F1-Score: 0.516139742864328\n",
      "LR Confusion Matrix:\n",
      "[[83 26 13 26]\n",
      " [22 50 30 32]\n",
      " [15 17 83 11]\n",
      " [20 14 12 46]]\n"
     ]
    }
   ],
   "source": [
    "# Replace 'binary' with the desired average setting ('micro', 'macro', 'weighted', or None)\n",
    "average_setting = 'macro'\n",
    "# Calculate precision, recall, and F1-score with the specified average setting and conf_matrix\n",
    "precision = precision_score(y_test_SVM, svm_predictions, average=average_setting)\n",
    "recall = recall_score(y_test_SVM, svm_predictions, average=average_setting)\n",
    "f1 = f1_score(y_test_SVM, svm_predictions, average=average_setting)\n",
    "conf_matrix = confusion_matrix(y_test_SVM, svm_predictions)\n",
    "\n",
    "# Print additional metrics\n",
    "print(\"LR Precision:\", precision)\n",
    "print(\"LR Recall:\", recall)\n",
    "print(\"LR F1-Score:\", f1)\n",
    "print(\"LR Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "35341546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.524\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.56      0.58       148\n",
      "           1       0.47      0.37      0.41       134\n",
      "           2       0.60      0.66      0.63       126\n",
      "           3       0.40      0.50      0.44        92\n",
      "\n",
      "    accuracy                           0.52       500\n",
      "   macro avg       0.52      0.52      0.52       500\n",
      "weighted avg       0.53      0.52      0.52       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "svm_accuracy = accuracy_score(y_test_SVM, svm_predictions)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test_SVM, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ad6e052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_val and y_val\n",
    "X_val_SVM = np.vstack(validation['W2v'].to_numpy())\n",
    "y_val_SVM = np.array(validation['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6ec51ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the Twitter-validation dataset\n",
    "validation['predicted SVM W2v'] = svm_model.predict(X_val_SVM)\n",
    "# Save the result to an Excel file\n",
    "validation.to_excel('SVM_validation_w2v.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7b724e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Tweet content</th>\n",
       "      <th>W2v</th>\n",
       "      <th>predicted RF W2v</th>\n",
       "      <th>predicted AB W2v</th>\n",
       "      <th>predicted LR W2v</th>\n",
       "      <th>predicted SVM W2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5328</td>\n",
       "      <td>2</td>\n",
       "      <td>[what, go, hearthston, ipad, delet, app, redow...</td>\n",
       "      <td>[0.10745893, -0.6231127, -0.01949474, 0.420772...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7618</td>\n",
       "      <td>2</td>\n",
       "      <td>[reason, offlin, franchis, lag, much, everi, p...</td>\n",
       "      <td>[-0.014914964, -0.7025625, -0.26694527, 0.0071...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7108</td>\n",
       "      <td>2</td>\n",
       "      <td>[johnson, johnson, enter, phase, trial, covid,...</td>\n",
       "      <td>[0.17915028, -0.08081439, 0.9860153, -0.341124...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10008</td>\n",
       "      <td>2</td>\n",
       "      <td>[ban, pubg, go, fix, anyth, gonna, make, every...</td>\n",
       "      <td>[0.14647946, -0.3018616, 0.040271103, 0.021447...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>[play, interest, quiz, amazon, tri, luck, chan...</td>\n",
       "      <td>[-0.09565098, -1.7299399, 0.42340872, 0.649577...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4891</td>\n",
       "      <td>3</td>\n",
       "      <td>[toronto, art, cultur, capit, canada, wonder, ...</td>\n",
       "      <td>[0.08433795, -0.4540689, 0.29474062, -0.054828...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4359</td>\n",
       "      <td>3</td>\n",
       "      <td>[actual, good, move, tot, bring, viewersi, one...</td>\n",
       "      <td>[0.102719866, -0.69867307, -0.09255285, 0.4414...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2652</td>\n",
       "      <td>0</td>\n",
       "      <td>[today, suck, time, drink, wine, n, play, bord...</td>\n",
       "      <td>[0.03667931, -0.6240968, -0.110848814, 0.68520...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>8069</td>\n",
       "      <td>0</td>\n",
       "      <td>[bought, fraction, microsoft, today, small, win]</td>\n",
       "      <td>[-0.13981943, -1.5053986, 0.4236864, -0.214958...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>6960</td>\n",
       "      <td>1</td>\n",
       "      <td>[johnson, johnson, stop, sell, talc, babi, pow...</td>\n",
       "      <td>[0.43969634, 0.18508025, 1.6390095, -0.754843,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tweet ID  sentiment                                      Tweet content  \\\n",
       "0        5328          2  [what, go, hearthston, ipad, delet, app, redow...   \n",
       "1        7618          2  [reason, offlin, franchis, lag, much, everi, p...   \n",
       "2        7108          2  [johnson, johnson, enter, phase, trial, covid,...   \n",
       "3       10008          2  [ban, pubg, go, fix, anyth, gonna, make, every...   \n",
       "4          49          1  [play, interest, quiz, amazon, tri, luck, chan...   \n",
       "..        ...        ...                                                ...   \n",
       "495      4891          3  [toronto, art, cultur, capit, canada, wonder, ...   \n",
       "496      4359          3  [actual, good, move, tot, bring, viewersi, one...   \n",
       "497      2652          0  [today, suck, time, drink, wine, n, play, bord...   \n",
       "498      8069          0   [bought, fraction, microsoft, today, small, win]   \n",
       "499      6960          1  [johnson, johnson, stop, sell, talc, babi, pow...   \n",
       "\n",
       "                                                   W2v  predicted RF W2v  \\\n",
       "0    [0.10745893, -0.6231127, -0.01949474, 0.420772...                 2   \n",
       "1    [-0.014914964, -0.7025625, -0.26694527, 0.0071...                 2   \n",
       "2    [0.17915028, -0.08081439, 0.9860153, -0.341124...                 2   \n",
       "3    [0.14647946, -0.3018616, 0.040271103, 0.021447...                 2   \n",
       "4    [-0.09565098, -1.7299399, 0.42340872, 0.649577...                 1   \n",
       "..                                                 ...               ...   \n",
       "495  [0.08433795, -0.4540689, 0.29474062, -0.054828...                 3   \n",
       "496  [0.102719866, -0.69867307, -0.09255285, 0.4414...                 3   \n",
       "497  [0.03667931, -0.6240968, -0.110848814, 0.68520...                 0   \n",
       "498  [-0.13981943, -1.5053986, 0.4236864, -0.214958...                 0   \n",
       "499  [0.43969634, 0.18508025, 1.6390095, -0.754843,...                 1   \n",
       "\n",
       "     predicted AB W2v  predicted LR W2v  predicted SVM W2v  \n",
       "0                   2                 2                  2  \n",
       "1                   2                 2                  2  \n",
       "2                   2                 2                  1  \n",
       "3                   2                 2                  2  \n",
       "4                   1                 1                  1  \n",
       "..                ...               ...                ...  \n",
       "495                 3                 3                  1  \n",
       "496                 3                 3                  0  \n",
       "497                 0                 0                  0  \n",
       "498                 0                 0                  1  \n",
       "499                 1                 1                  1  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cdefa6",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "013b0184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Correct Predictions: 255\n"
     ]
    }
   ],
   "source": [
    "result_SVM = pd.read_excel('SVM_validation_w2v.xlsx')\n",
    "true_sentiment = result_SVM['sentiment']\n",
    "predicted_sentiment = result_SVM['predicted SVM W2v']\n",
    "# Calculate the number of correct predictions\n",
    "correct_predictions = sum(true_sentiment == predicted_sentiment)\n",
    "# Print the number of correct predictions\n",
    "print(f'Number of Correct Predictions: {correct_predictions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a9c706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c633312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec7312e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c27a744",
   "metadata": {},
   "source": [
    "###############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb94ef",
   "metadata": {},
   "source": [
    "از اینجا به بهد من یه روشی رو رفتم برای word 2vec و خواستم باشه."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "my6fq-q3WgsT",
   "metadata": {
    "id": "my6fq-q3WgsT"
   },
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8evkVmuWYzbS",
   "metadata": {
    "id": "8evkVmuWYzbS"
   },
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b817e11",
   "metadata": {
    "id": "9b817e11"
   },
   "outputs": [],
   "source": [
    "# Python program to generate word vectors using Word2Vec\n",
    "# importing all necessary modules\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "data = []\n",
    "# Check for NaN values and replace them with an empty string\n",
    "# training['Tweet content'].fillna('', inplace=True)\n",
    "# Define the function to tokenize sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae90eb",
   "metadata": {
    "id": "f9ae90eb"
   },
   "outputs": [],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YHN5panWwvI-",
   "metadata": {
    "id": "YHN5panWwvI-"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41bd9e4",
   "metadata": {
    "id": "a41bd9e4"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "f = training['Tweet content']\n",
    "# iterate through each sentence in the file\n",
    "\n",
    "def tokenize_sentence(sentence):\n",
    "    # tokenize the sentence into words\n",
    "     if isinstance(sentence, str):  # Check if the value is a string\n",
    "        return word_tokenize(sentence)\n",
    "\n",
    "\n",
    "# Apply the tokenization function to the 'Tweet content' column\n",
    "training['Tweet content'] = training['Tweet content'].apply(tokenize_sentence)\n",
    "test['Tweet content'] = test['Tweet content'].apply(tokenize_sentence)\n",
    "validation['Tweet content'] = validation['Tweet content'].apply(tokenize_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885cb17e",
   "metadata": {
    "id": "885cb17e"
   },
   "outputs": [],
   "source": [
    "training['Tweet content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760BgYzszWUC",
   "metadata": {
    "id": "760BgYzszWUC"
   },
   "outputs": [],
   "source": [
    "test['Tweet content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc76904",
   "metadata": {
    "id": "7cc76904"
   },
   "outputs": [],
   "source": [
    "# Create CBOW model\n",
    "model1 = gensim.models.Word2Vec(training['Tweet content'], min_count = 1, vector_size = 100, window = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cUNUJDGWzVRA",
   "metadata": {
    "id": "cUNUJDGWzVRA"
   },
   "outputs": [],
   "source": [
    "# Create CBOW model\n",
    "model2 = gensim.models.Word2Vec(test['Tweet content'], min_count = 1, vector_size = 100, window = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urwEqJ4hzva2",
   "metadata": {
    "id": "urwEqJ4hzva2"
   },
   "outputs": [],
   "source": [
    "# Create CBOW model\n",
    "model3 = gensim.models.Word2Vec(validation['Tweet content'], min_count = 1, vector_size = 100, window = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9893b73f",
   "metadata": {
    "id": "9893b73f"
   },
   "outputs": [],
   "source": [
    "print(\"Cosine similarity betweene' \" +\n",
    "               \" : \",\n",
    "    model1.wv.similarity('see', 'look'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b337e3",
   "metadata": {
    "collapsed": true,
    "id": "33b337e3"
   },
   "outputs": [],
   "source": [
    "X= list(model1.wv.index_to_key)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e48f69",
   "metadata": {
    "id": "04e48f69"
   },
   "outputs": [],
   "source": [
    "word_to_check = \"so\"\n",
    "if word_to_check in model1.wv:\n",
    "    word_embedding = model1.wv[word_to_check]\n",
    "print(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed0bc3",
   "metadata": {
    "id": "59ed0bc3"
   },
   "outputs": [],
   "source": [
    "# def get_embedding(sentence):\n",
    "#     embeddings = [model1.wv[word] for word in sentence if word in model1.wv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725fb5f",
   "metadata": {
    "id": "2725fb5f"
   },
   "outputs": [],
   "source": [
    "training['Tweet content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9da65af",
   "metadata": {
    "id": "e9da65af"
   },
   "outputs": [],
   "source": [
    "def embed_word_lists(list_of_lists, model):\n",
    "    vec = np.zeros(100).reshape((1, 100))\n",
    "    count = 0\n",
    "    embeddings = []\n",
    "\n",
    "    for word_list in list_of_lists:\n",
    "\n",
    "        try:\n",
    "            vec +=\n",
    "\n",
    "            word_embeddings = [model.wv[word] for word in word_list if word in model.wv]\n",
    "\n",
    "        if not word_embeddings:\n",
    "            # Append zeros if no embeddings are available for the entire list\n",
    "            embeddings.append([0] * model.vector_size)\n",
    "        else:\n",
    "            # Concatenate the embeddings for each word in the list\n",
    "            list_embedding = np.concatenate(word_embeddings)\n",
    "            embeddings.append(list_embedding)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Apply the embedding function to your list of lists\n",
    "embedded_lists = embed_word_lists(training['Tweet content'], model1)\n",
    "embedded_lists_test = embed_word_lists(test['Tweet content'], model2)\n",
    "embedded_lists_validation = embed_word_lists(validation['Tweet content'], model3)\n",
    "\n",
    "# 'embedded_lists' now contains the Word2Vec embeddings for each inner list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b84ae",
   "metadata": {
    "id": "771b84ae"
   },
   "outputs": [],
   "source": [
    "print(len(embedded_lists[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd269159",
   "metadata": {
    "id": "dd269159"
   },
   "outputs": [],
   "source": [
    "training['embedding'] = embedded_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SuZb9Dsx0JD9",
   "metadata": {
    "id": "SuZb9Dsx0JD9"
   },
   "outputs": [],
   "source": [
    "test['embedding'] = embedded_lists_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_hQuBDbJ0QBt",
   "metadata": {
    "id": "_hQuBDbJ0QBt"
   },
   "outputs": [],
   "source": [
    "validation['embedding'] = embedded_lists_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f3b82d",
   "metadata": {
    "id": "75f3b82d"
   },
   "outputs": [],
   "source": [
    "# training['embedding'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56b34b",
   "metadata": {
    "id": "da56b34b"
   },
   "outputs": [],
   "source": [
    "print(training[['Tweet content', 'embedding']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492550c3",
   "metadata": {
    "id": "492550c3"
   },
   "outputs": [],
   "source": [
    "data=model1.wv.most_similar(\"see\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053d359",
   "metadata": {
    "id": "9053d359"
   },
   "outputs": [],
   "source": [
    "# Assuming 'embedding' is a column in your DataFrame containing the embedding vectors\n",
    "X_train = training['embedding']  # Convert the list of arrays to a 2D array\n",
    "y_train = training['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf8746",
   "metadata": {
    "id": "14bf8746"
   },
   "outputs": [],
   "source": [
    "# Find the maximum length of sequences in the 'embedding' column\n",
    "max_length = max(training['embedding'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dBC0I9Ud_4rA",
   "metadata": {
    "id": "dBC0I9Ud_4rA"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MwN9DSWB_6Ea",
   "metadata": {
    "id": "MwN9DSWB_6Ea"
   },
   "outputs": [],
   "source": [
    "# Find the maximum length of sequences in the 'embedding' column\n",
    "max_length = max(training['embedding'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vugb7B7V_6Hl",
   "metadata": {
    "id": "Vugb7B7V_6Hl"
   },
   "outputs": [],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e9474c",
   "metadata": {
    "id": "c3e9474c"
   },
   "source": [
    "# Creating Word Embeddings using Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f59f0",
   "metadata": {
    "id": "af5f59f0"
   },
   "outputs": [],
   "source": [
    "X_data, y_data = np.array(training['Tweet content']), np.array(training['sentiment'])\n",
    "X_data_v, y_data_v = np.array(validation['Tweet content']), np.array(validation['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefefd2b",
   "metadata": {
    "id": "cefefd2b"
   },
   "outputs": [],
   "source": [
    "X_data = X_data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b0c77a",
   "metadata": {
    "id": "48b0c77a"
   },
   "outputs": [],
   "source": [
    "X_data_v = X_data_v.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f34e5",
   "metadata": {
    "id": "053f34e5"
   },
   "outputs": [],
   "source": [
    "type(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a52fad",
   "metadata": {
    "id": "44a52fad"
   },
   "outputs": [],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f56b99",
   "metadata": {
    "collapsed": true,
    "id": "c0f56b99"
   },
   "outputs": [],
   "source": [
    "X_data_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d5706",
   "metadata": {
    "id": "8f4d5706"
   },
   "outputs": [],
   "source": [
    "Embedding_dimensions = 100\n",
    "# Creating Word2Vec training dataset.\n",
    "Word2vec_train_data = list(map(lambda x: x.split(), X_data))\n",
    "Word2vec_train_data_v = list(map(lambda x: x.split(), X_data_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab3194",
   "metadata": {
    "id": "94ab3194"
   },
   "outputs": [],
   "source": [
    "# u_data = ['im getting on borderlands and i will murder you all']\n",
    "# Word2vec_train_data = list(map(lambda x: x.split(), u_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d22adf1",
   "metadata": {
    "collapsed": true,
    "id": "0d22adf1"
   },
   "outputs": [],
   "source": [
    "Word2vec_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0277b62",
   "metadata": {
    "collapsed": true,
    "id": "e0277b62"
   },
   "outputs": [],
   "source": [
    "Word2vec_train_data_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c333bd",
   "metadata": {
    "id": "87c333bd"
   },
   "source": [
    " word2vec_model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad45bcb",
   "metadata": {
    "id": "aad45bcb"
   },
   "outputs": [],
   "source": [
    "# Defining the model and training it.\n",
    "word2vec_model = Word2Vec(Word2vec_train_data,\n",
    "                 vector_size=Embedding_dimensions,\n",
    "                 workers=8,\n",
    "                 min_count=5)\n",
    "\n",
    "print(\"Vocabulary Length:\", len(word2vec_model.wv.key_to_index))#unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af90cd7",
   "metadata": {
    "id": "2af90cd7"
   },
   "outputs": [],
   "source": [
    "word2vec_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ae7c30",
   "metadata": {
    "id": "63ae7c30"
   },
   "source": [
    "word2vec_model valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c152d847",
   "metadata": {
    "id": "c152d847"
   },
   "outputs": [],
   "source": [
    "# Defining the model and training it.\n",
    "word2vec_model_v = Word2Vec(Word2vec_train_data_v,\n",
    "                 vector_size=Embedding_dimensions,\n",
    "                 workers=8,\n",
    "                 min_count=5)\n",
    "\n",
    "print(\"Vocabulary Length:\", len(word2vec_model_v.wv.key_to_index))#unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc84642",
   "metadata": {
    "id": "7bc84642"
   },
   "source": [
    "# Tokenizing and Padding datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69a8b1",
   "metadata": {
    "id": "ef69a8b1"
   },
   "outputs": [],
   "source": [
    "# Defining the model input length.\n",
    "input_length = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61bb891",
   "metadata": {
    "id": "d61bb891"
   },
   "outputs": [],
   "source": [
    "vocab_length = 15000\n",
    "tokenizer_t = Tokenizer(filters=\"\", lower=False, oov_token=\"<oov>\")\n",
    "tokenizer_t.fit_on_texts(X_data)\n",
    "tokenizer_t.num_words = vocab_length\n",
    "print(\"Tokenizer vocab length:\", vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55749a77",
   "metadata": {
    "id": "55749a77"
   },
   "outputs": [],
   "source": [
    "vocab_length = 15000\n",
    "tokenizer_v = Tokenizer(filters=\"\", lower=False, oov_token=\"<oov>\")\n",
    "tokenizer_v.fit_on_texts(X_data_v)\n",
    "tokenizer_v.num_words = vocab_length\n",
    "print(\"Tokenizer vocab length:\", vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94a947",
   "metadata": {
    "id": "5e94a947"
   },
   "outputs": [],
   "source": [
    "X_data = pad_sequences(tokenizer_t.texts_to_sequences(X_data), maxlen=input_length)\n",
    "X_data_v = pad_sequences(tokenizer_v.texts_to_sequences(X_data_v), maxlen=input_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917103cf",
   "metadata": {
    "id": "917103cf"
   },
   "source": [
    "# Creating Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6969c",
   "metadata": {
    "id": "26c6969c"
   },
   "outputs": [],
   "source": [
    "embedding_matrix_t = np.zeros((vocab_length, Embedding_dimensions))\n",
    "\n",
    "for word, token in tokenizer_t.word_index.items():\n",
    "    if word2vec_model.wv.__contains__(word):\n",
    "        embedding_matrix[token] = word2vec_model.wv.__getitem__(word)\n",
    "\n",
    "print(\"Embedding Matrix Shape:\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e64022",
   "metadata": {
    "id": "42e64022"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50925e62",
   "metadata": {
    "id": "50925e62"
   },
   "outputs": [],
   "source": [
    "embedding_matrix_v = np.zeros((vocab_length, Embedding_dimensions))\n",
    "\n",
    "for word, token in tokenizer_v.word_index.items():\n",
    "    if word2vec_model_v.wv.__contains__(word):\n",
    "        embedding_matrix_v[token] = word2vec_model_v.wv.__getitem__(word)\n",
    "\n",
    "print(\"Embedding Matrix Shape:\", embedding_matrix_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d04a5",
   "metadata": {
    "id": "db2d04a5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c204478",
   "metadata": {
    "id": "2c204478"
   },
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2643838d",
   "metadata": {
    "id": "2643838d"
   },
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    embedding_layer = Embedding(input_dim = vocab_length,\n",
    "                                output_dim = Embedding_dimensions,\n",
    "                                weights=[embedding_matrix_t],\n",
    "                                input_length=input_length,\n",
    "                                trainable=False)\n",
    "\n",
    "    model = Sequential([\n",
    "        embedding_layer,\n",
    "        Bidirectional(LSTM(100, dropout=0.3, return_sequences=True)),\n",
    "        Bidirectional(LSTM(100, dropout=0.3, return_sequences=True)),\n",
    "        Conv1D(100, 5, activation='relu'),\n",
    "        GlobalMaxPool1D(),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ],\n",
    "    name=\"Sentiment_Model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c41c7",
   "metadata": {
    "id": "969c41c7"
   },
   "outputs": [],
   "source": [
    "training_model = getModel()\n",
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba92e781",
   "metadata": {
    "id": "ba92e781"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import keras_metrics as km\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c3f04",
   "metadata": {
    "id": "a18c3f04"
   },
   "outputs": [],
   "source": [
    "pip install keras-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2564fc9f",
   "metadata": {
    "id": "2564fc9f"
   },
   "outputs": [],
   "source": [
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "             EarlyStopping(monitor='val_accuracy', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1152da8",
   "metadata": {
    "id": "f1152da8"
   },
   "outputs": [],
   "source": [
    "training_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC(), tf.keras.metrics.BinaryCrossentropy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5feb08",
   "metadata": {
    "id": "8e5feb08"
   },
   "outputs": [],
   "source": [
    "history = training_model.fit(\n",
    "    X_data, y_data,\n",
    "    batch_size=1024,\n",
    "    epochs=5,\n",
    "    validation_data=(X_data_v, y_data_v),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3704b3",
   "metadata": {
    "id": "fd3704b3"
   },
   "outputs": [],
   "source": [
    "acc,  val_acc  = history.history['accuracy'], history.history['val_accuracy']\n",
    "loss, val_loss = history.history['loss'], history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f272cba7",
   "metadata": {
    "id": "f272cba7"
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import nltk\n",
    "raw_text = \"\"\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The result is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\"\"\".split()\n",
    "# tokenize sentences in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ac5a32ec",
   "metadata": {
    "id": "ac5a32ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extract': ['of', 'artificial', ')', 'linguistics', 'interactions'],\n",
       " 'information': ['within',\n",
       "  'subfield',\n",
       "  'intelligence',\n",
       "  'technology',\n",
       "  'accurately'],\n",
       " 'insights': ['them', 'technology', 'contextual', 'data', 'program']}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "tokenized_corpus = [wpt.tokenize(document) for document in raw_text]\n",
    "# Set values for various parameters\n",
    "feature_size = 100    # Word vector dimensionality\n",
    "window_context = 30          # Context window size\n",
    "min_word_count = 1   # Minimum word count\n",
    "sample = 1e-3   # Downsample setting for frequent words\n",
    "w2v_model = word2vec.Word2Vec(tokenized_corpus, vector_size=feature_size,\n",
    "                          window=window_context, min_count=min_word_count,\n",
    "                          sample=sample)\n",
    "# view similar words based on gensim's model\n",
    "similar_words = {search_term: [item[0] for item in w2v_model.wv.most_similar([search_term], topn=5)]\n",
    "                  for search_term in ['extract','information','insights']}\n",
    "similar_words"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
